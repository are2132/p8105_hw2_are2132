p8105\_hw2\_are2132
================
Alison Elgass

# Problem 1

First we load in the Mr. Wheel Data

``` r
#read & clean data from sheet 1 mr. wheel
wheel_data = 
  read_excel(
    path = "./hw2 data/trash_wheel_data.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols(1:14) #don't read last column
  ) %>% 
  
  janitor::clean_names() %>% 
  filter(dumpster != "NA") %>% #omit non-dumpster rows
  mutate(sports_balls = as.integer(sports_balls)) #round

#read & clean precip data 2018
precip_18 = 
  read_excel(
    path = "./hw2 data/trash_wheel_data.xlsx", 
    sheet = "2018 Precipitation" ,
    skip = 1 #skip first row (header)
  ) %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(year = "2018")

#read & clean precip data 2017
precip_17 = 
  read_excel(
    path = "./hw2 data/trash_wheel_data.xlsx", 
    sheet = "2017 Precipitation" ,
    skip = 1 #skip first row (header)
  ) %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(year = "2017")
  
#now combine 2017 + 2018 precip data into one
precip_17_18 = 
  bind_rows(precip_17, precip_18) %>% 
  mutate(month = month.name[month]) #spell out month names
```

## Discussion

We used the “Mr. Trash Wheel Data” to create a dataframe called
`wheel_data`. It should be noted that in creating & cleaning this
dataset, we excluded the non-dumpster-specific rows, namely the monthly
totals.

The resulting dataset `wheel_data` has 285 rows and 14 columns.

The greatest amount of trash by weight that Mr. Trash Wheel picked up in
one dumpster was 5.62 tons, which occurred on 2015-05-17 in Dumpster
Number \# 62. Not surprisingly, this also corresponded to the highest
number of homes powered from one dumpster, which was about 94 homes.

By volume, the greatest amount was 20 yards<sup>3</sup>, which occurred
on 2014-08-13 in Dumpster Number \# 27.

Next we read in the precipitation data from 2017 and 2018 (note that we
only have data through July 2018). We then combined these nicely into a
dataframe `precip_17_18`, which has 19 rows and 3 columns.

The total precipitation in 2018 through July was 23.5 inches of rain.

The median number of sports ball in a dumpster in 2017 was 8 balls.

# Problem 2

First we read in and tidy the political counts data

``` r
pols_month = 
  read_csv(file = "./hw2 data/538_data/pols-month.csv") %>%
  janitor::clean_names() %>% 
  
  #break up date into 3 columns
  separate(col = mon, into = c("year","month","day"), 
           sep = "-", convert = TRUE) %>% 
  
  #spell out months
  mutate(month = month.name[month]) %>% 
  

  #create new column "president", initialize as gop col
  mutate(president = prez_gop) %>% 
  
  #replace gop = 0 values with "dem"
  mutate(president = 
           replace(president, president == 0, "dem")) %>% 
  #replace remaining (gop nonzero) values with "gop"
  mutate(president = 
           replace(president, president!="dem", "gop")) %>%
 
  #delete 3 columns, including day
  select(-c(prez_dem, prez_gop, day))
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

Next we read in and tidy the stock market data

``` r
snp_data = 
  read_csv(file = "./hw2 data/538_data/snp.csv") %>% 
  janitor::clean_names() %>% 
  
  #break up date into 3 columns
  separate(col = date, into = c("month","day","year"), 
           sep = "/", convert = TRUE) %>% 
  
  #arrange rows by date
  arrange(year, month) %>% 
  
  #spell out months
  mutate(month = month.name[month]) %>%
  
  #get rid of day column
  select(-day) %>% 
  
  #order so cols = year then month
  select(year, everything())
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

Finally we read in and tidy the unemployment data

``` r
unemploy_data = 
  read_csv(file = "./hw2 data/538_data/unemployment.csv") %>% 
  #note we don't want to clean names yet
  #since months must be capitalized
  
  #pivot wide to long
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemploy_rate"
  ) %>% 

  #spell out months: Jan > 1 > January
  mutate(month = month.name[match(month, month.abb)]) %>% 
    
  #now clean up names so Year > year
  janitor::clean_names() 
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

``` r
  #mutate(year = as.integer(year))
```

Now let’s combine the datasets into one

``` r
final_data538 = left_join(pols_month, snp_data) %>%
  left_join(unemploy_data)
```

    ## Joining, by = c("year", "month")
    ## Joining, by = c("year", "month")

## Discussion

We imported and cleaned three datasets from the FiveThiryEight data,
which was used to create a “p-hacking” simulation in the context of the
question “which political party is better for the U.S. economy?”

The first dataset was `pols_month`, which records the number of
congressmen and women in office by party at various dates, as well as
the party of the president. We cleaned the data so each date was divided
into year and month, and created one single `president` column with
values indicating either “gop” (Republican) or “dem” (Democrat). One
interesting detail from the original dataset is that from August -
December 1974, there were 2 GOP presidents recorded. Presumably this
corresponds to the period in which Richard Nixon had resigned, turning
over the presidency to his VP, Gerald Ford. This detail is not apparent,
however, in our final dataset, which only indicates the party of the
president, rather than a number.

The final dataset `pols_month` spans from January 1947 to June 2015. It
has 822 rows and 9 columns.

The next dataset was `snp_data`, which records the closing value of the
S\&P stock market index on various dates (variable `close`). We cleaned
this dataset to be consistent with the political data, including only
year and month values. This dataset has 787 rows and 3 columns.

The final dataset `unemploy_data` records the unemployment rate for each
month in a year. We tidied this data so that each row corresponds to a
month and year, and we called the variable of interest `unemploy_rate`.
The final dataset has 816 rows and 3 columns.

Lastly we combined all three datasets into one, which we called
`final_data538`. Since it starts with `pols_month` it also has 822 rows.
It has 11 columns, which corresponds to the 9 variables from
`pols_month` plus the stock market value variable `close`, and the
unemployment rate `unemploy_rate`. Note that `snp_data` only starts at
January 1950, and `unemploy_data` only starts at January 1948 so their
values in the first few months of `final_data538` are marked “NA”.

# Problem 3

First load & tidy baby name data

``` r
baby_names = 
  read_csv("./hw2 data/baby_names_data.csv") %>% 
  janitor::clean_names() %>% 
  
  rename(name = childs_first_name) %>%
  
  #make ethnicity labels consistent throughout
  mutate(
    ethnicity = replace(ethnicity, 
                        ethnicity == "ASIAN AND PACI",
                        "ASIAN AND PACIFIC ISLANDER"),
    ethnicity = replace(ethnicity, 
                        ethnicity == "BLACK NON HISP",
                        "BLACK NON HISPANIC"),
    ethnicity = replace(ethnicity, 
                        ethnicity == "WHITE NON HISP",
                        "WHITE NON HISPANIC"),
    ) %>%
  #unique(pull(baby_names,ethnicity))

  #convert all names to caps just for consistency
  mutate(
    name = str_to_upper(name)
  ) %>%
  
  #remove duplicate rows 
  distinct()
```

    ## Parsed with column specification:
    ## cols(
    ##   `Year of Birth` = col_double(),
    ##   Gender = col_character(),
    ##   Ethnicity = col_character(),
    ##   `Child's First Name` = col_character(),
    ##   Count = col_double(),
    ##   Rank = col_double()
    ## )

## “Olivia” name popularity chart

``` r
#separate baby_names data by year
baby_16 = filter(baby_names, year_of_birth == "2016")
baby_15 = filter(baby_names, year_of_birth == "2015")
baby_14 = filter(baby_names, year_of_birth == "2014")
baby_13 = filter(baby_names, year_of_birth == "2013")
baby_12 = filter(baby_names, year_of_birth == "2012")
baby_11 = filter(baby_names, year_of_birth == "2011")

#find row #'s for each Olivia in each year (should be 4)
rows16 = which(pull(baby_16,name) == "OLIVIA")
rows15 = which(pull(baby_15,name) == "OLIVIA")
rows14 = which(pull(baby_14,name) == "OLIVIA")
rows13 = which(pull(baby_13,name) == "OLIVIA")
rows12 = which(pull(baby_12,name) == "OLIVIA")
rows11 = which(pull(baby_11,name) == "OLIVIA")

#create mini tibble with row #, ethnicity, rank
tbl_16 = tibble("row" = rows16, 
         "ethnicity" = pull(baby_16,ethnicity)[rows16],
         "rank" = pull(baby_16,rank)[rows16]) 
tbl_15 = tibble("row" = rows15, 
         "ethnicity" = pull(baby_15,ethnicity)[rows15],
         "rank" = pull(baby_15,rank)[rows15]) 
tbl_14 = tibble("row" = rows14, 
         "ethnicity" = pull(baby_14,ethnicity)[rows14],
         "rank" = pull(baby_14,rank)[rows14])
tbl_13 = tibble("row" = rows13, 
         "ethnicity" = pull(baby_13,ethnicity)[rows13],
         "rank" = pull(baby_13,rank)[rows13]) 
tbl_12 = tibble("row" = rows12, 
         "ethnicity" = pull(baby_12,ethnicity)[rows12],
         "rank" = pull(baby_12,rank)[rows12])
tbl_11 = tibble("row" = rows11, 
         "ethnicity" = pull(baby_11,ethnicity)[rows11],
         "rank" = pull(baby_11,rank)[rows11]) 

#combine ranks into one pretty table
olivia_df = tibble("ethnicity" = pull(tbl_16, ethnicity),
                   "2011" = pull(tbl_11, rank),
                   "2012" = pull(tbl_12, rank),
                   "2013" = pull(tbl_13, rank),
                   "2014" = pull(tbl_14, rank),
                   "2015" = pull(tbl_15, rank),
                   "2016" = pull(tbl_16, rank))

olivia_df
```

    ## # A tibble: 4 x 7
    ##   ethnicity                  `2011` `2012` `2013` `2014` `2015` `2016`
    ##   <chr>                       <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>
    ## 1 ASIAN AND PACIFIC ISLANDER      4      3      3      1      1      1
    ## 2 BLACK NON HISPANIC             10      8      6      8      4      8
    ## 3 HISPANIC                       18     22     22     16     16     13
    ## 4 WHITE NON HISPANIC              2      4      1      1      1      1
