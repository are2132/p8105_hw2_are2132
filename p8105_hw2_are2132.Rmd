---
title: "p8105_hw2_are2132"
author: Alison Elgass
output: github_document
---

```{r setup, include=FALSE}

library(tidyverse)
library(readxl)
```

# Problem 1
First we load in the Mr. Wheel Data
```{r}
#read & clean data from sheet 1 mr. wheel
wheel_data = 
  read_excel(
    path = "./hw2 data/trash_wheel_data.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols(1:14) #don't read last column
  ) %>% 
  
  janitor::clean_names() %>% 
  filter(dumpster != "NA") %>% #omit non-dumpster rows
  mutate(sports_balls = as.integer(sports_balls)) #round

#read & clean precip data 2018
precip_18 = 
  read_excel(
    path = "./hw2 data/trash_wheel_data.xlsx", 
    sheet = "2018 Precipitation" ,
    skip = 1 #skip first row (header)
  ) %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(year = "2018")

#read & clean precip data 2017
precip_17 = 
  read_excel(
    path = "./hw2 data/trash_wheel_data.xlsx", 
    sheet = "2017 Precipitation" ,
    skip = 1 #skip first row (header)
  ) %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(year = "2017")
  
#now combine 2017 + 2018 precip data into one
precip_17_18 = 
  bind_rows(precip_17, precip_18) %>% 
  mutate(month = month.name[month]) #spell out month names
```

## Discussion
We used the "Mr. Trash Wheel Data" to create a dataframe called `wheel_data`. It should be noted that in creating & cleaning this dataset, we excluded the non-dumpster-specific rows, namely the monthly totals.  
  
The resulting dataset `wheel_data` has `r nrow(wheel_data)` rows and `r ncol(wheel_data)` columns.  
  
The greatest amount of trash by weight that Mr. Trash Wheel picked up in one dumpster was `r max(pull(wheel_data, weight_tons))` tons, which occurred on `r wheel_data[which.max(pull(wheel_data,weight_tons)),"date"]` in Dumpster Number # `r which.max(pull(wheel_data,weight_tons))`. Not surprisingly, this also corresponded to the highest number of homes powered from one dumpster, which was about `r round(wheel_data[which.max(pull(wheel_data,weight_tons)),"homes_powered"])` homes.

By volume, the greatest amount was `r max(pull(wheel_data, volume_cubic_yards))` yards^3^, which occurred on `r wheel_data[which.max(pull(wheel_data,volume_cubic_yards)),"date"]` in Dumpster Number # `r which.max(pull(wheel_data,volume_cubic_yards))`.  
  

Next we read in the precipitation data from 2017 and 2018 (note that we only have data through July 2018). We then combined these nicely into a dataframe `precip_17_18`, which has `r nrow(precip_17_18)` rows and `r ncol(precip_17_18)` columns.  
  
The total precipitation in 2018 through July was `r sum(pull(precip_18, total))` inches of rain.  
  
The median number of sports ball in a dumpster in 2017 was `r median(pull(filter(wheel_data, year == "2017"), sports_balls))` balls.


# Problem 2
First we read in and tidy the political counts data
```{r pols}

pols_month = 
  read_csv(file = "./hw2 data/538_data/pols-month.csv") %>%
  janitor::clean_names() %>% 
  
  #break up date into 3 columns
  separate(col = mon, into = c("year","month","day"), 
           sep = "-", convert = TRUE) %>% 
  
  #spell out months
  mutate(month = month.name[month]) %>% 
  

  #create new column "president", initialize as gop col
  mutate(president = prez_gop) %>% 
  
  #replace gop = 0 values with "dem"
  mutate(president = 
           replace(president, president == 0, "dem")) %>% 
  #replace remaining (gop nonzero) values with "gop"
  mutate(president = 
           replace(president, president!="dem", "gop")) %>%
 
  #delete 3 columns, including day
  select(-c(prez_dem, prez_gop, day))
  
```

Next we read in and tidy the stock market data
```{r snp}
snp_data = 
  read_csv(file = "./hw2 data/538_data/snp.csv") %>% 
  janitor::clean_names() %>% 
  
  #break up date into 3 columns
  separate(col = date, into = c("month","day","year"), 
           sep = "/", convert = TRUE) %>% 
  
  #arrange rows by date
  arrange(year, month) %>% 
  
  #spell out months
  mutate(month = month.name[month]) %>%
  
  #get rid of day column
  select(-day) %>% 
  
  #order so cols = year then month
  select(year, everything())

```


Finally we read in and tidy the unemployment data
```{r}
unemploy_data = 
  read_csv(file = "./hw2 data/538_data/unemployment.csv") %>% 
  #note we don't want to clean names yet
  #since months must be capitalized
  
  #pivot wide to long
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemploy_rate"
  ) %>% 

  #spell out months: Jan > 1 > January
  mutate(month = month.name[match(month, month.abb)]) %>% 
    
  #now clean up names so Year > year
  janitor::clean_names() 
  #mutate(year = as.integer(year))


```

Now let's combine the datasets into one
```{r}
final_data538 = left_join(pols_month, snp_data) %>%
  left_join(unemploy_data)
```

## Discussion
We imported and cleaned three datasets from the FiveThiryEight data, which was used to create a "p-hacking" simulation in the context of the question "which political party is better for the U.S. economy?"  
  
The first dataset was `pols_month`, which records the number of congressmen and women in office by party at various dates, as well as the party of the president. We cleaned the data so each date was divided into year and month, and created one single `president` column with values indicating either "gop" (Republican) or "dem" (Democrat). One interesting detail from the original dataset is that from August - December 1974, there were 2 GOP presidents recorded. Presumably this corresponds to the period in which Richard Nixon had resigned, turning over the presidency to his VP, Gerald Ford. This detail is not apparent, however, in our final dataset, which only indicates the party of the president, rather than a number.  

The final dataset `pols_month` spans from `r pull(pols_month, month)[1]` `r pull(pols_month, year)[1]` to `r last(pull(pols_month, month))` `r last(pull(pols_month, year))`. It has `r nrow(pols_month)` rows and `r ncol(pols_month)` columns.  
  
The next dataset was `snp_data`, which records the closing value of the S&P stock market index on various dates (variable `close`). We cleaned this dataset to be consistent with the political data, including only year and month values. This dataset has `r nrow(snp_data)` rows and `r ncol(snp_data)` columns.

The final dataset `unemploy_data` records the unemployment rate for each month in a year. We tidied this data so that each row corresponds to a month and year, and we called the variable of interest `unemploy_rate`. The final dataset has `r nrow(unemploy_data)` rows and `r ncol(unemploy_data)` columns.  
  
Lastly we combined all three datasets into one, which we called `final_data538`. Since it starts with `pols_month` it also has `r nrow(final_data538)` rows. It has `r ncol(final_data538)` columns, which corresponds to the 9 variables from `pols_month` plus the stock market value variable `close`, and the unemployment rate `unemploy_rate`. Note that `snp_data` only starts at `r pull(snp_data, month)[1]` `r pull(snp_data, year)[1]`, and `unemploy_data` only starts at `r pull(unemploy_data, month)[1]` `r pull(unemploy_data, year)[1]` so their values in the first few months of `final_data538` are marked "NA".

