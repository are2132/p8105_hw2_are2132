---
title: "p8105_hw2_are2132"
author: Alison Elgass
output: github_document
---

```{r setup, include=FALSE}

library(tidyverse)
library(readxl)
```

# Problem 1
First we load in the Mr. Wheel Data
```{r}
#read & clean data from sheet 1 mr. wheel
wheel_data = 
  read_excel(
    path = "./hw2 data/trash_wheel_data.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols(1:14) #don't read last column
  ) %>% 
  
  janitor::clean_names() %>% 
  filter(dumpster != "NA") %>% #omit non-dumpster rows
  mutate(sports_balls = as.integer(sports_balls)) #round

#read & clean precip data 2018
precip_18 = 
  read_excel(
    path = "./hw2 data/trash_wheel_data.xlsx", 
    sheet = "2018 Precipitation" ,
    skip = 1 #skip first row (header)
  ) %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(year = "2018")

#read & clean precip data 2017
precip_17 = 
  read_excel(
    path = "./hw2 data/trash_wheel_data.xlsx", 
    sheet = "2017 Precipitation" ,
    skip = 1 #skip first row (header)
  ) %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(year = "2017")
  
#now combine 2017 + 2018 precip data into one
precip_17_18 = 
  bind_rows(precip_17, precip_18) %>% 
  mutate(month = month.name[month]) #spell out month names
```

## Discussion
We used the "Mr. Trash Wheel Data" to create a dataframe called `wheel_data`. It should be noted that in creating & cleaning this dataset, we excluded the non-dumpster-specific rows, namely the monthly totals.  
  
The resulting dataset `wheel_data` has `r nrow(wheel_data)` rows and `r ncol(wheel_data)` columns.  
  
The greatest amount of trash by weight that Mr. Trash Wheel picked up in one dumpster was `r max(pull(wheel_data, weight_tons))` tons, which occurred on `r wheel_data[which.max(pull(wheel_data,weight_tons)),"date"]` in Dumpster Number # `r which.max(pull(wheel_data,weight_tons))`. Not surprisingly, this also corresponded to the highest number of homes powered from one dumpster, which was about `r round(wheel_data[which.max(pull(wheel_data,weight_tons)),"homes_powered"])` homes.

By volume, the greatest amount was `r max(pull(wheel_data, volume_cubic_yards))` yards^3^, which occurred on `r wheel_data[which.max(pull(wheel_data,volume_cubic_yards)),"date"]` in Dumpster Number # `r which.max(pull(wheel_data,volume_cubic_yards))`.  
  

Next we read in the precipitation data from 2017 and 2018 (note that we only have data through July 2018). We then combined these nicely into a dataframe `precip_17_18`, which has `r nrow(precip_17_18)` rows and `r ncol(precip_17_18)` columns.  
  
The total precipitation in 2018 through July was `r sum(pull(precip_18, total))` inches of rain.  
  
The median number of sports ball in a dumpster in 2017 was `r median(pull(filter(wheel_data, year == "2017"), sports_balls))` balls.


# Problem 2
First we read in and tidy the political counts data
```{r pols}

pols_month = 
  read_csv(file = "./hw2 data/538_data/pols-month.csv") %>%
  janitor::clean_names() %>% 
  
  #break up date into 3 columns
  separate(col = mon, into = c("year","month","day"), 
           sep = "-", convert = TRUE) %>% 
  
  #spell out months
  mutate(month = month.name[month]) %>% 
  

  #create new column "president", initialize as gop col
  mutate(president = prez_gop) %>% 
  
  #replace gop = 0 values with "dem"
  mutate(president = 
           replace(president, president == 0, "dem")) %>% 
  #replace remaining (gop nonzero) values with "gop"
  mutate(president = 
           replace(president, president!="dem", "gop")) %>%
 
  #delete 3 columns
  select(-c(prez_dem,prez_gop,day))
  
```

Next we read in and tidy the stock market data
```{r snp}
snp_data = 
  read_csv(file = "./hw2 data/538_data/snp.csv") %>% 
  janitor::clean_names() %>% 
  
  #break up date into 3 columns
  separate(col = date, into = c("month","day","year"), 
           sep = "/", convert = TRUE) %>% 
  
  #arrange by date
  arrange(year, month) %>% 
  
  #spell out months
  mutate(month = month.name[month]) %>%
  
  #get rid of day column
  select(-day) %>% 
  
  #order so cols = year then month
  select(year, everything())

```


Finally we read in and tidy the unemployment data
```{r}
unemploy_data = 
  read_csv(file = "./hw2 data/538_data/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemploy_rate"
  )

```

Now let's combine the datasets into one
```{r}
stepping_stone = left_join(pols_month, snp_data)
final_data538 = left_join(stepping_stone, unemploy_data)
```

## Discussion
Explain briefly what each dataset contained, and describe the resulting dataset (e.g. give the dimension, range of years, and names of key variables).


